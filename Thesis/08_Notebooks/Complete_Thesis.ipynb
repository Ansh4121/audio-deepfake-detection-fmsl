{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üéì Audio Deepfake Detection using FMSL - ASVspoof2019 LA Dataset\n",
        "\n",
        "## Overview\n",
        "This notebook provides a comprehensive implementation and evaluation of Frequency-Modulated Spectral Loss (FMSL) for audio deepfake detection using the **ASVspoof2019 LA dataset**.\n",
        "\n",
        "### Key Features:\n",
        "- **8 Baseline Models** (Maze1-Maze8) \n",
        "- **8 FMSL-Enhanced Models**\n",
        "- **ASVspoof2019 LA Dataset** (Logical Access track)\n",
        "- **Professional Evaluation Framework**\n",
        "- **Publication-Ready Visualizations**\n",
        "\n",
        "### Dataset Information:\n",
        "- **ASVspoof2019 LA**: Logical Access track\n",
        "- **Training**: 25,380 bonafide + 25,380 spoofed utterances\n",
        "- **Evaluation**: 7,355 bonafide + 63,882 spoofed utterances\n",
        "- **Sample Rate**: 16 kHz\n",
        "- **Format**: FLAC audio files\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Environment Setup\n",
        "\n",
        "### 1.1 Google Colab Setup & Drive Mount\n",
        "rEA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive and setup paths\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# ASVspoof2019 LA Dataset paths\n",
        "PROJECT_ROOT = \"/content/drive/MyDrive/ASVspoof2019/LA/2021/LA/Baseline-RawNet2\"\n",
        "DATA_ROOT = \"/content/sample_data/data\"\n",
        "ASVSPOOF_LA_ROOT = \"/content/drive/MyDrive/ASVspoof2019/Extract/LA\"\n",
        "PROTOCOLS_PATH = f\"{ASVSPOOF_LA_ROOT}/ASVspoof2019_LA_cm_protocols\"\n",
        "\n",
        "# Training and evaluation data paths\n",
        "TRAIN_DATA_PATH = f\"{ASVSPOOF_LA_ROOT}/ASVspoof2019_LA_train\"\n",
        "EVAL_DATA_PATH = f\"{ASVSPOOF_LA_ROOT}/ASVspoof2019_LA_eval\"\n",
        "DEV_DATA_PATH = f\"{ASVSPOOF_LA_ROOT}/ASVspoof2019_LA_dev\"\n",
        "\n",
        "# Add project to Python path\n",
        "sys.path.append(PROJECT_ROOT)\n",
        "os.chdir(PROJECT_ROOT)\n",
        "\n",
        "print(\"‚úÖ ASVspoof2019 LA Environment Setup Complete!\")\n",
        "print(f\"üìÅ Project Root: {PROJECT_ROOT}\")\n",
        "print(f\"üìä Data Root: {DATA_ROOT}\")\n",
        "print(f\"üéØ ASVspoof2019 LA Root: {ASVSPOOF_LA_ROOT}\")\n",
        "print(f\"üìã Protocols: {PROTOCOLS_PATH}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2 Package Installation for ASVspoof20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install packages optimized for ASVspoof2019\n",
        "!pip install --upgrade pip setuptools wheel\n",
        "\n",
        "# Core ML packages\n",
        "!pip install torch==2.3.1+cu118 torchvision==0.18.1+cu118 torchaudio==2.3.1+cu118 --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install transformers==4.41.2\n",
        "!pip install librosa==0.9.2 soundfile pandas pyyaml scikit-learn\n",
        "!pip install tensorboardX==2.6 numba==0.58.1\n",
        "!pip install matplotlib seaborn plotly\n",
        "\n",
        "print(\"‚úÖ ASVspoof2019 packages installed successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.3 Import Libraries\n",
        "kind of config "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries for ASVspoof2019 LA\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import json\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "\n",
        "# Audio processing\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchaudio\n",
        "\n",
        "# Transformers for Wav2Vec2\n",
        "from transformers import Wav2Vec2Model, Wav2Vec2Config\n",
        "\n",
        "# Evaluation metrics\n",
        "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report\n",
        "from sklearn.metrics import accuracy_score, precision_recall_curve\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ All libraries imported successfully!\")\n",
        "print(f\"üîß PyTorch: {torch.__version__}\")\n",
        "print(f\"üîß CUDA Available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"üîß GPU: {torch.cuda.get_device_name(0)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. ASVspoof2019 LA Dataset Preparation\n",
        "\n",
        "### 2.1 Dataset Verification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify ASVspoof2019 LA dataset structure\n",
        "def verify_asvspoof2019_la():\n",
        "    \"\"\"Verify ASVspoof2019 LA dataset availability and structure\"\"\"\n",
        "    \n",
        "    print(\"üîç Verifying ASVspoof2019 LA Dataset...\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Check main directories\n",
        "    directories = {\n",
        "        \"ASVspoof2019 LA Root\": ASVSPOOF_LA_ROOT,\n",
        "        \"Training Data\": TRAIN_DATA_PATH,\n",
        "        \"Evaluation Data\": EVAL_DATA_PATH,\n",
        "        \"Development Data\": DEV_DATA_PATH,\n",
        "        \"Protocols\": PROTOCOLS_PATH\n",
        "    }\n",
        "    \n",
        "    for name, path in directories.items():\n",
        "        if os.path.exists(path):\n",
        "            print(f\"‚úÖ {name}: {path}\")\n",
        "            # Count files if it's a data directory\n",
        "            if \"Data\" in name:\n",
        "                flac_files = len([f for f in os.listdir(path) if f.endswith('.flac')])\n",
        "                print(f\"   üìä FLAC files: {flac_files}\")\n",
        "        else:\n",
        "            print(f\"‚ùå {name}: {path} (Not found)\")\n",
        "    \n",
        "    # Check protocol files\n",
        "    protocol_files = [\n",
        "        \"ASVspoof2019.LA.cm.train.trn.txt\",\n",
        "        \"ASVspoof2019.LA.cm.dev.trl.txt\", \n",
        "        \"ASVspoof2019.LA.cm.eval.trl.txt\"\n",
        "    ]\n",
        "    \n",
        "    print(f\"\\nüìã Protocol Files:\")\n",
        "    for protocol in protocol_files:\n",
        "        protocol_path = os.path.join(PROTOCOLS_PATH, protocol)\n",
        "        if os.path.exists(protocol_path):\n",
        "            print(f\"‚úÖ {protocol}\")\n",
        "        else:\n",
        "            print(f\"‚ùå {protocol} (Not found)\")\n",
        "    \n",
        "    return all(os.path.exists(path) for path in directories.values())\n",
        "\n",
        "# Verify dataset\n",
        "dataset_ready = verify_asvspoof2019_la()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "dy hard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "s use cond"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "h of thos model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üéì Audio Deepfake Detection using FMSL - Complete Thesis Notebook\n",
        "\n",
        "## Overview\n",
        "This notebook provides a comprehensive implementation and evaluation of Frequency-Modulated Spectral Loss (FMSL) for audio deepfake detection. It includes:\n",
        "\n",
        "- **8 Baseline Models** (Maze1-Maze8)\n",
        "- **8 FMSL-Enhanced Models** \n",
        "- **Comprehensive Evaluation Framework**\n",
        "- **Professional Analysis and Visualization**\n",
        "\n",
        "## Table of Contents\n",
        "1. [Environment Setup](#1-environment-setup)\n",
        "2. [Data Preparation](#2-data-preparation)\n",
        "3. [Model Training](#3-model-training)\n",
        "4. [Model Evaluation](#4-model-evaluation)\n",
        "5. [Results Analysis](#5-results-analysis)\n",
        "6. [Thesis Visualization](#6-thesis-visualization)\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Environment Setup\n",
        "\n",
        "### 1.1 Google Colab Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set up paths\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Project paths\n",
        "PROJECT_ROOT = \"/content/drive/MyDrive/ASVspoof2019/LA/2021/LA/Baseline-RawNet2\"\n",
        "DATA_ROOT = \"/content/sample_data/data\"\n",
        "PROTOCOLS_PATH = \"/content/drive/MyDrive/ASVspoof2019/Extract/LA/ASVspoof2019_LA_cm_protocols\"\n",
        "\n",
        "# Add project to Python path\n",
        "sys.path.append(PROJECT_ROOT)\n",
        "\n",
        "# Change to project directory\n",
        "os.chdir(PROJECT_ROOT)\n",
        "\n",
        "print(\"‚úÖ Environment setup complete!\")\n",
        "print(f\"üìÅ Project root: {PROJECT_ROOT}\")\n",
        "print(f\"üìä Data root: {DATA_ROOT}\")\n",
        "print(f\"üìã Protocols: {PROTOCOLS_PATH}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2 Package Installation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install --upgrade pip setuptools wheel\n",
        "\n",
        "# Install core ML packages\n",
        "!pip install torch==2.3.1+cu118 torchvision==0.18.1+cu118 torchaudio==2.3.1+cu118 --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install transformers==4.41.2\n",
        "!pip install librosa==0.9.2 soundfile pandas pyyaml scikit-learn\n",
        "!pip install tensorboardX==2.6\n",
        "!pip install numba==0.58.1\n",
        "\n",
        "print(\"‚úÖ All packages installed successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.3 Import Required Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import core libraries\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import json\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "\n",
        "# Data processing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "\n",
        "# Deep learning\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchaudio\n",
        "\n",
        "# Transformers\n",
        "from transformers import Wav2Vec2Model, Wav2Vec2Config\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ All libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Preparation\n",
        "\n",
        "### 2.1 Data Setup and Verification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data preparation and verification\n",
        "def setup_data_environment():\n",
        "    \"\"\"Setup data environment and verify data availability\"\"\"\n",
        "    \n",
        "    # Create data directory\n",
        "    os.makedirs(DATA_ROOT, exist_ok=True)\n",
        "    \n",
        "    # Check if data exists\n",
        "    data_sources = {\n",
        "        \"Training Data\": f\"{DATA_ROOT}/ASVspoof2019_LA_train\",\n",
        "        \"Evaluation Data\": f\"{DATA_ROOT}/ASVspoof2019_LA_eval\", \n",
        "        \"Protocols\": PROTOCOLS_PATH\n",
        "    }\n",
        "    \n",
        "    print(\"üîç Checking data availability...\")\n",
        "    for name, path in data_sources.items():\n",
        "        if os.path.exists(path):\n",
        "            print(f\"‚úÖ {name}: {path}\")\n",
        "        else:\n",
        "            print(f\"‚ùå {name}: {path} (Not found)\")\n",
        "    \n",
        "    return data_sources\n",
        "\n",
        "# Setup data environment\n",
        "data_status = setup_data_environment()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Model Training\n",
        "\n",
        "### 3.1 Training Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training configuration\n",
        "TRAINING_CONFIG = {\n",
        "    'architecture': {\n",
        "        'filts': [128, [128, 128], [128, 256]],\n",
        "        'nb_fc_node': 1024,\n",
        "        'nb_classes': 2,\n",
        "        'sample_rate': 16000,\n",
        "        'first_conv': 251,\n",
        "        'dropout_rate': 0.3\n",
        "    },\n",
        "    'wav2vec2': {\n",
        "        'wav2vec2_model_name': 'facebook/wav2vec2-base-960h',\n",
        "        'wav2vec2_output_dim': 768,\n",
        "        'wav2vec2_freeze': True\n",
        "    },\n",
        "    'fmsl': {\n",
        "        'fmsl_type': 'prototype',\n",
        "        'fmsl_n_prototypes': 3,\n",
        "        'fmsl_s': 32.0,\n",
        "        'fmsl_m': 0.45,\n",
        "        'fmsl_enable_lsa': False\n",
        "    },\n",
        "    'training': {\n",
        "        'batch_size': 12,\n",
        "        'lr': 0.0001,\n",
        "        'weight_decay': 0.0001,\n",
        "        'grad_clip_norm': 1.0,\n",
        "        'num_epochs': 5,\n",
        "        'seed': 1234\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"‚úÖ Training configuration loaded!\")\n",
        "print(f\"üìä Architecture: {TRAINING_CONFIG['architecture']}\")\n",
        "print(f\"üéØ Training params: {TRAINING_CONFIG['training']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Model Training Commands\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training commands for all models\n",
        "def get_training_commands():\n",
        "    \"\"\"Generate training commands for all models\"\"\"\n",
        "    \n",
        "    # Baseline models\n",
        "    baseline_models = ['maze1', 'maze2', 'maze3', 'maze4', 'maze5', 'maze6', 'maze7', 'maze8']\n",
        "    \n",
        "    print(\"üöÄ BASELINE MODEL TRAINING COMMANDS\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    for model in baseline_models:\n",
        "        cmd = f\"python {model}.py --track=LA --loss=cce --lr={TRAINING_CONFIG['training']['lr']} --batch_size={TRAINING_CONFIG['training']['batch_size']} --num_epochs={TRAINING_CONFIG['training']['num_epochs']} --database_path={DATA_ROOT} --protocols_path={PROTOCOLS_PATH}\"\n",
        "        print(f\"\\n{model}:\")\n",
        "        print(f\"  {cmd}\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"üöÄ FMSL-ENHANCED MODEL TRAINING COMMANDS\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    for model in baseline_models:\n",
        "        cmd = f\"python {model}_fmsl_standardized.py --track=LA --lr={TRAINING_CONFIG['training']['lr']} --batch_size={TRAINING_CONFIG['training']['batch_size']} --num_epochs={TRAINING_CONFIG['training']['num_epochs']} --database_path={DATA_ROOT} --protocols_path={PROTOCOLS_PATH}\"\n",
        "        print(f\"\\n{model}_fmsl:\")\n",
        "        print(f\"  {cmd}\")\n",
        "    \n",
        "    print(\"\\n‚úÖ All training commands generated!\")\n",
        "    print(\"üí° Uncomment and run specific commands as needed.\")\n",
        "\n",
        "# Generate training commands\n",
        "get_training_commands()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Model Evaluation\n",
        "\n",
        "### 4.1 Evaluation Commands\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluation commands for all models\n",
        "def get_evaluation_commands():\n",
        "    \"\"\"Generate evaluation commands for all models\"\"\"\n",
        "    \n",
        "    baseline_models = ['maze1', 'maze2', 'maze3', 'maze4', 'maze5', 'maze6', 'maze7', 'maze8']\n",
        "    \n",
        "    print(\"üîç BASELINE MODEL EVALUATION COMMANDS\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    for model in baseline_models:\n",
        "        cmd = f\"python {model}_eval.py --model_type {model} --model_path /path/to/{model}_model.pth --batch_size 128\"\n",
        "        print(f\"\\n{model}:\")\n",
        "        print(f\"  {cmd}\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"üîç FMSL-ENHANCED MODEL EVALUATION COMMANDS\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    for model in baseline_models:\n",
        "        cmd = f\"python {model}_eval.py --model_type {model}_fmsl --model_path /path/to/{model}_fmsl_model.pth --batch_size 128\"\n",
        "        print(f\"\\n{model}_fmsl:\")\n",
        "        print(f\"  {cmd}\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"üìä COMPREHENSIVE EVALUATION\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    comp_cmd = f\"python comprehensive_evaluation.py --data_dir {DATA_ROOT} --protocol_file {PROTOCOLS_PATH}/ASVspoof2019.LA.cm.eval.trl.txt --output_dir evaluation_results --batch_size 128\"\n",
        "    print(f\"\\nComprehensive Evaluation:\")\n",
        "    print(f\"  {comp_cmd}\")\n",
        "    \n",
        "    print(\"\\n‚úÖ All evaluation commands generated!\")\n",
        "    print(\"üí° Update model paths with actual trained model locations.\")\n",
        "\n",
        "# Generate evaluation commands\n",
        "get_evaluation_commands()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Results Analysis\n",
        "\n",
        "### 5.1 Performance Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Performance visualization function\n",
        "def create_performance_plots():\n",
        "    \"\"\"Create performance comparison plots\"\"\"\n",
        "    print(\"üìä Creating performance plots...\")\n",
        "    \n",
        "    # Set up the plot style\n",
        "    plt.style.use('seaborn-v0_8-whitegrid')\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "    fig.suptitle('Audio Deepfake Detection Performance Comparison', fontsize=16, fontweight='bold')\n",
        "    \n",
        "    # Sample data (replace with actual results)\n",
        "    models = ['Maze1', 'Maze2', 'Maze3', 'Maze4', 'Maze5', 'Maze6', 'Maze7', 'Maze8']\n",
        "    baseline_eer = [0.15, 0.12, 0.10, 0.08, 0.07, 0.06, 0.05, 0.04]  # Placeholder values\n",
        "    fmsl_eer = [0.12, 0.09, 0.07, 0.05, 0.04, 0.03, 0.02, 0.01]      # Placeholder values\n",
        "    improvement = [(b-f)/b*100 for b, f in zip(baseline_eer, fmsl_eer)]\n",
        "    \n",
        "    # Plot 1: EER Comparison\n",
        "    x = np.arange(len(models))\n",
        "    width = 0.35\n",
        "    \n",
        "    axes[0, 0].bar(x - width/2, baseline_eer, width, label='Baseline', alpha=0.8, color='skyblue')\n",
        "    axes[0, 0].bar(x + width/2, fmsl_eer, width, label='FMSL-Enhanced', alpha=0.8, color='lightcoral')\n",
        "    axes[0, 0].set_title('EER Comparison')\n",
        "    axes[0, 0].set_ylabel('Equal Error Rate (EER)')\n",
        "    axes[0, 0].set_xticks(x)\n",
        "    axes[0, 0].set_xticklabels(models, rotation=45)\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Plot 2: Improvement\n",
        "    axes[0, 1].bar(models, improvement, alpha=0.8, color='green')\n",
        "    axes[0, 1].set_title('FMSL Improvement')\n",
        "    axes[0, 1].set_ylabel('Improvement (%)')\n",
        "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Plot 3: Performance Distribution\n",
        "    axes[1, 0].hist(baseline_eer, alpha=0.7, label='Baseline', bins=5, color='skyblue', edgecolor='black')\n",
        "    axes[1, 0].hist(fmsl_eer, alpha=0.7, label='FMSL-Enhanced', bins=5, color='lightcoral', edgecolor='black')\n",
        "    axes[1, 0].set_title('Performance Distribution')\n",
        "    axes[1, 0].set_xlabel('EER')\n",
        "    axes[1, 0].set_ylabel('Frequency')\n",
        "    axes[1, 0].legend()\n",
        "    axes[1, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Plot 4: Model Complexity vs Performance\n",
        "    complexity = [1, 2, 3, 4, 5, 6, 7, 8]\n",
        "    axes[1, 1].scatter(complexity, baseline_eer, alpha=0.8, label='Baseline', s=100, color='skyblue', edgecolor='black')\n",
        "    axes[1, 1].scatter(complexity, fmsl_eer, alpha=0.8, label='FMSL-Enhanced', s=100, color='lightcoral', edgecolor='black')\n",
        "    axes[1, 1].set_title('Model Complexity vs Performance')\n",
        "    axes[1, 1].set_xlabel('Model Complexity')\n",
        "    axes[1, 1].set_ylabel('EER')\n",
        "    axes[1, 1].legend()\n",
        "    axes[1, 1].grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"‚úÖ Performance plots created successfully!\")\n",
        "    print(\"üí° Replace placeholder data with actual evaluation results.\")\n",
        "\n",
        "# Create performance plots\n",
        "create_performance_plots()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
