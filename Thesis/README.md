# Audio Deepfake Detection using Frequency-Modulated Spectral Loss (FMSL)

## Overview

This repository contains the complete implementation and evaluation of a novel Frequency-Modulated Spectral Loss (FMSL) approach for audio deepfake detection using the **ASVspoof2019 LA dataset**. The research presents a comprehensive comparison between baseline models and FMSL-enhanced models across 8 different architectural configurations.

## ğŸš€ Quick Start

```bash
# Clone the repository
git clone https://github.com/yourusername/audio-deepfake-detection-fmsl.git
cd audio-deepfake-detection-fmsl

# Setup environment (Linux/Mac)
chmod +x setup.sh
./setup.sh

# Setup environment (Windows)
setup.bat

# Activate virtual environment
source venv/bin/activate  # Linux/Mac
# or
venv\Scripts\activate.bat  # Windows

# Run basic tests
python tests/test_basic.py
```

## ğŸ“Š Dataset

- **ASVspoof2019 LA** (Logical Access track)
- **Training**: 25,380 bonafide + 25,380 spoofed utterances
- **Evaluation**: 7,355 bonafide + 63,882 spoofed utterances
- **Sample Rate**: 16 kHz
- **Format**: FLAC audio files

## ğŸ“ Repository Structure

```
Thesis_Project/
â”œâ”€â”€ ğŸ“¦ Essential Files
â”‚   â”œâ”€â”€ .gitignore                   # Git ignore rules
â”‚   â”œâ”€â”€ requirements.txt             # Python dependencies
â”‚   â”œâ”€â”€ setup.py                     # Package installation
â”‚   â”œâ”€â”€ environment.yml              # Conda environment
â”‚   â”œâ”€â”€ setup.sh                     # Linux/Mac setup script
â”‚   â”œâ”€â”€ setup.bat                    # Windows setup script
â”‚   â””â”€â”€ tests/                       # Test suite
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ test_basic.py            # Basic functionality tests
â”‚
â”œâ”€â”€ ğŸ§  Models
â”‚   â”œâ”€â”€ 01_Baseline_Models/          # Original models without FMSL
â”‚   â”‚   â”œâ”€â”€ maze1.py                 # Baseline RawNet2 with Fixed SincConv
â”‚   â”‚   â”œâ”€â”€ maze2.py                 # Wav2Vec2 + SpecAugment + Focal Loss
â”‚   â”‚   â”œâ”€â”€ maze3.py                 # RawNetSinc + SE Transformer
â”‚   â”‚   â”œâ”€â”€ maze4.py                 # RawNetSinc + SpecAugment
â”‚   â”‚   â”œâ”€â”€ maze5.py                 # RawNetSinc + SpecAugment + Focal Loss
â”‚   â”‚   â”œâ”€â”€ maze6.py                 # RawNet + Wav2Vec2 + Transformer
â”‚   â”‚   â”œâ”€â”€ maze7.py                 # RawNet + Wav2Vec2 + SpecAugment + Focal Loss
â”‚   â”‚   â”œâ”€â”€ maze8.py                 # Advanced RawNet + Wav2Vec2 + Transformer
â”‚   â”‚   â””â”€â”€ main.py                  # Main training script
â”‚   â””â”€â”€ 02_FMSL_Enhanced_Models/     # FMSL-enhanced versions
â”‚       â”œâ”€â”€ maze1_fmsl.py            # Maze1 + FMSL
â”‚       â”œâ”€â”€ maze1_fmsl_standardized.py
â”‚       â”œâ”€â”€ maze2_fmsl.py            # Maze2 + FMSL
â”‚       â”œâ”€â”€ maze2_fmsl_standardized.py
â”‚       â”œâ”€â”€ ...                      # All other FMSL variants
â”‚       â””â”€â”€ main_fmsl_standardized.py
â”œâ”€â”€ 02_Evaluation_Scripts/           # Model evaluation scripts
â”‚   â”œâ”€â”€ Maze1_eval.py
â”‚   â”œâ”€â”€ Maze2_Eval.py
â”‚   â”œâ”€â”€ ...                          # All evaluation scripts
â”‚   â””â”€â”€ Main_eval.py
â”œâ”€â”€ 03_Data_Processing/              # Data preparation and processing
â”‚   â”œâ”€â”€ colab_setup.py
â”‚   â”œâ”€â”€ setup_asvspoof2021.py
â”‚   â””â”€â”€ download_la_keys.py
â”œâ”€â”€ 04_Results_and_Analysis/         # Results, analysis, and visualizations
â”‚   â”œâ”€â”€ evaluation_results/
â”‚   â”œâ”€â”€ thesis_results/
â”‚   â”œâ”€â”€ comprehensive_fmsl_analysis.py
â”‚   â””â”€â”€ thesis_automation.py
â”œâ”€â”€ ğŸ“š Documentation/                # Complete documentation
â”‚   â”œâ”€â”€ INSTALLATION.md              # Installation guide
â”‚   â”œâ”€â”€ USAGE.md                     # Usage guide
â”‚   â”œâ”€â”€ TROUBLESHOOTING.md           # Troubleshooting guide
â”‚   â”œâ”€â”€ GOOGLE_COLAB_GUIDE.md
â”‚   â”œâ”€â”€ MAZE5_EVALUATION_GUIDE.md
â”‚   â”œâ”€â”€ THESIS_ANALYSIS_USAGE_GUIDE.md
â”‚   â””â”€â”€ ...                          # All documentation files
â”œâ”€â”€ ğŸ”§ Utilities/                    # Utility functions and tools
â”‚   â”œâ”€â”€ fmsl_advanced.py
â”‚   â”œâ”€â”€ fmsl_standardized_config.py
â”‚   â”œâ”€â”€ checkpoint_manager.py
â”‚   â”œâ”€â”€ unified_model_evaluator.py
â”‚   â”œâ”€â”€ data_preprocessor.py         # Data preprocessing utilities
â”‚   â””â”€â”€ model_trainer.py             # Automated training script
â”œâ”€â”€ 07_Configuration_Files/          # Model configuration files
â”‚   â”œâ”€â”€ model_config.yaml
â”‚   â”œâ”€â”€ model_config_Maze6.yaml
â”‚   â””â”€â”€ models_config_template.json
â”œâ”€â”€ ğŸ““ Notebooks/                    # Jupyter notebooks
â”‚   â”œâ”€â”€ Complete_Thesis.ipynb        # Main thesis notebook
â”‚   â”œâ”€â”€ Colab_CPU_Test_Notebook.ipynb
â”‚   â”œâ”€â”€ FMSL_Maze_Models_Colab.ipynb
â”‚   â””â”€â”€ GOOGLE_COLAB_SEQUENTIAL_TRAINING.ipynb
â””â”€â”€ ğŸ“„ LaTeX/                        # LaTeX source and PDFs (in WUT-Thesis/)
    â”œâ”€â”€ Thesis.pdf
    â””â”€â”€ Audio Deepfake Detection FMSL Research.pdf
```

## Key Features

### 1. FMSL (Frequency-Modulated Spectral Loss)
- **Novel Contribution**: A new loss function specifically designed for audio deepfake detection
- **Frequency-Domain Enhancement**: Improves feature learning in the frequency domain
- **Geometric Learning**: Incorporates geometric constraints for better classification

### 2. Comprehensive Model Comparison
- **8 Baseline Models**: From simple RawNet2 to complex Wav2Vec2 + Transformer architectures
- **8 FMSL-Enhanced Models**: Each baseline model enhanced with FMSL
- **Standardized Configurations**: Ensures fair comparison across all models

### 3. Standardized Architecture
All models follow a consistent configuration:
- **Input**: 16kHz audio samples
- **Architecture**: `filts: [128, [128, 128], [128, 256]]`
- **FC Layer**: 1024 nodes
- **Classes**: 2 (bonafide vs spoof)
- **Training**: 5 epochs, batch size 12, AdamW optimizer

## Model Descriptions

### Baseline Models (Maze1-Maze8)

1. **Maze1**: Baseline RawNet2 with Fixed SincConv
   - Fixed (non-trainable) SincConv filters
   - 6 residual blocks
   - Establishes baseline performance

2. **Maze2**: Wav2Vec2 + SpecAugment + Focal Loss
   - Pre-trained Wav2Vec2 feature extractor
   - SpecAugment data augmentation
   - Focal Loss for class imbalance

3. **Maze3**: RawNetSinc + SE Transformer
   - Trainable SincConv filters
   - Squeeze-Excitation blocks
   - Transformer encoder

4. **Maze4**: RawNetSinc + SpecAugment
   - Trainable SincConv
   - SpecAugment augmentation
   - Standard residual architecture

5. **Maze5**: RawNetSinc + SpecAugment + Focal Loss
   - Combines Maze4 with Focal Loss
   - Better handling of class imbalance

6. **Maze6**: RawNet + Wav2Vec2 + Transformer
   - Multi-modal feature fusion
   - Wav2Vec2 + RawNet features
   - Transformer for sequence modeling

7. **Maze7**: RawNet + Wav2Vec2 + SpecAugment + Focal Loss
   - Most comprehensive baseline
   - All advanced techniques combined

8. **Maze8**: Advanced RawNet + Wav2Vec2 + Transformer
   - Latest architectural improvements
   - Optimized for performance

### FMSL-Enhanced Models
Each baseline model has a corresponding FMSL-enhanced version:
- **FMSL Integration**: Novel frequency-domain processing
- **Geometric Learning**: Enhanced feature representation
- **Consistent Architecture**: Same base structure as baseline

## Configuration Verification

### Standardized Parameters
All models use the following standardized configuration:

```python
STANDARDIZED_CONFIG = {
    'architecture': {
        'filts': [128, [128, 128], [128, 256]],
        'nb_fc_node': 1024,
        'nb_classes': 2,
        'sample_rate': 16000,
        'first_conv': 251,
        'dropout_rate': 0.3
    },
    'wav2vec2': {
        'wav2vec2_model_name': 'facebook/wav2vec2-base-960h',
        'wav2vec2_output_dim': 768,
        'wav2vec2_freeze': True
    },
    'fmsl': {
        'fmsl_type': 'prototype',
        'fmsl_n_prototypes': 3,
        'fmsl_s': 32.0,
        'fmsl_m': 0.45,
        'fmsl_enable_lsa': False
    },
    'training': {
        'batch_size': 12,
        'lr': 0.0001,
        'weight_decay': 0.0001,
        'grad_clip_norm': 1.0,
        'num_epochs': 5,
        'seed': 1234
    }
}
```

### Verification Results
âœ… **All maze configurations are consistent with standardized settings**
- Baseline and FMSL models have identical base architectures
- Only FMSL-specific parameters differ between baseline and FMSL versions
- Ensures fair comparison across all model variants

## Usage

### Training Models

```bash
# Train baseline model
python maze1.py --database_path /path/to/data --protocols_path /path/to/protocols

# Train FMSL-enhanced model
python maze1_fmsl.py --database_path /path/to/data --protocols_path /path/to/protocols
```

### Evaluation

```bash
# Evaluate model
python Maze1_eval.py --model_path /path/to/model.pth --eval_output scores.txt
```

### Configuration

All models use standardized configurations defined in `fmsl_standardized_config.py`:

```python
from fmsl_standardized_config import get_standardized_config

# Get baseline configuration
config = get_standardized_config("baseline")

# Get FMSL configuration
config = get_standardized_config("fmsl")
```

## Results

The repository includes comprehensive evaluation results showing:
- **Performance Comparison**: Baseline vs FMSL-enhanced models
- **Statistical Analysis**: Significance testing and confidence intervals
- **Visualization**: ROC curves, confusion matrices, and performance plots
- **Ablation Studies**: Component-wise analysis of FMSL contributions

## Key Findings

1. **FMSL Effectiveness**: FMSL consistently improves performance across all model architectures
2. **Architectural Consistency**: Standardized configurations ensure fair comparison
3. **Frequency-Domain Benefits**: FMSL's frequency-domain processing provides significant advantages
4. **Scalability**: FMSL enhancement works across different model complexities

## Dependencies

- Python 3.8+
- PyTorch 1.9+
- Transformers 4.0+
- Librosa
- Scikit-learn
- TensorBoard
- Matplotlib
- Seaborn

## Citation

If you use this work, please cite:

```bibtex
@thesis{your_thesis_2024,
  title={Audio Deepfake Detection using Frequency-Modulated Spectral Loss},
  author={Your Name},
  year={2024},
  school={Your University}
}
```

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Contact

For questions or collaborations, please contact [your.email@university.edu].

---

**Note**: This repository contains the complete implementation and evaluation of the FMSL approach for audio deepfake detection, providing a comprehensive framework for reproducible research in this domain.
